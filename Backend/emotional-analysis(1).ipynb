{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-10-28T09:24:43.334922Z","iopub.execute_input":"2023-10-28T09:24:43.335263Z","iopub.status.idle":"2023-10-28T09:24:43.646619Z","shell.execute_reply.started":"2023-10-28T09:24:43.335238Z","shell.execute_reply":"2023-10-28T09:24:43.645489Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"/kaggle/input/emotion-detection-from-text/tweet_emotions.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"data=pd.read_csv('/kaggle/input/emotion-detection-from-text/tweet_emotions.csv')\nprint(data.columns)\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-27T17:44:36.447128Z","iopub.execute_input":"2023-10-27T17:44:36.448001Z","iopub.status.idle":"2023-10-27T17:44:36.545625Z","shell.execute_reply.started":"2023-10-27T17:44:36.447957Z","shell.execute_reply":"2023-10-27T17:44:36.544320Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Index(['tweet_id', 'sentiment', 'content'], dtype='object')\n","output_type":"stream"},{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"     tweet_id   sentiment                                            content\n0  1956967341       empty  @tiffanylue i know  i was listenin to bad habi...\n1  1956967666     sadness  Layin n bed with a headache  ughhhh...waitin o...\n2  1956967696     sadness                Funeral ceremony...gloomy friday...\n3  1956967789  enthusiasm               wants to hang out with friends SOON!\n4  1956968416     neutral  @dannycastillo We want to trade with someone w...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweet_id</th>\n      <th>sentiment</th>\n      <th>content</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1956967341</td>\n      <td>empty</td>\n      <td>@tiffanylue i know  i was listenin to bad habi...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1956967666</td>\n      <td>sadness</td>\n      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1956967696</td>\n      <td>sadness</td>\n      <td>Funeral ceremony...gloomy friday...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1956967789</td>\n      <td>enthusiasm</td>\n      <td>wants to hang out with friends SOON!</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1956968416</td>\n      <td>neutral</td>\n      <td>@dannycastillo We want to trade with someone w...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"data['sentiment'].unique()","metadata":{"execution":{"iopub.status.busy":"2023-10-27T17:44:36.548102Z","iopub.execute_input":"2023-10-27T17:44:36.548553Z","iopub.status.idle":"2023-10-27T17:44:36.559750Z","shell.execute_reply.started":"2023-10-27T17:44:36.548510Z","shell.execute_reply":"2023-10-27T17:44:36.558770Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"array(['empty', 'sadness', 'enthusiasm', 'neutral', 'worry', 'surprise',\n       'love', 'fun', 'hate', 'happiness', 'boredom', 'relief', 'anger'],\n      dtype=object)"},"metadata":{}}]},{"cell_type":"code","source":"new_df = pd.DataFrame(columns=['content','sentiment'])\n\n# Iterating over the DataFrame and copying rows that match the specific item\nfor index, row in data.iterrows():\n    if row['sentiment'] in ['sadness', 'neutral', 'love', 'happiness', 'anger']:\n        new_row = {'content': row['content'], 'sentiment': row['sentiment']}\n        new_df.loc[len(new_df.index)] = [row['content'], row['sentiment']] \n","metadata":{"execution":{"iopub.status.busy":"2023-10-27T17:44:36.561406Z","iopub.execute_input":"2023-10-27T17:44:36.562077Z","iopub.status.idle":"2023-10-27T17:45:17.139262Z","shell.execute_reply.started":"2023-10-27T17:44:36.562044Z","shell.execute_reply":"2023-10-27T17:45:17.138016Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"len(new_df)","metadata":{"execution":{"iopub.status.busy":"2023-10-27T17:45:17.141900Z","iopub.execute_input":"2023-10-27T17:45:17.142277Z","iopub.status.idle":"2023-10-27T17:45:17.149853Z","shell.execute_reply.started":"2023-10-27T17:45:17.142238Z","shell.execute_reply":"2023-10-27T17:45:17.148503Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"22964"},"metadata":{}}]},{"cell_type":"code","source":"for i in ['sadness', 'neutral', 'love', 'happiness', 'anger']:\n    new_df[i] = new_df['sentiment'].apply(lambda x: 1 if x == i else 0)\nnew_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-27T17:45:17.151250Z","iopub.execute_input":"2023-10-27T17:45:17.151626Z","iopub.status.idle":"2023-10-27T17:45:17.270460Z","shell.execute_reply.started":"2023-10-27T17:45:17.151596Z","shell.execute_reply":"2023-10-27T17:45:17.269172Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"                                             content sentiment  sadness  \\\n0  Layin n bed with a headache  ughhhh...waitin o...   sadness        1   \n1                Funeral ceremony...gloomy friday...   sadness        1   \n2  @dannycastillo We want to trade with someone w...   neutral        0   \n3  I should be sleep, but im not! thinking about ...   sadness        1   \n4            @charviray Charlene my love. I miss you   sadness        1   \n\n   neutral  love  happiness  anger  \n0        0     0          0      0  \n1        0     0          0      0  \n2        1     0          0      0  \n3        0     0          0      0  \n4        0     0          0      0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>content</th>\n      <th>sentiment</th>\n      <th>sadness</th>\n      <th>neutral</th>\n      <th>love</th>\n      <th>happiness</th>\n      <th>anger</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n      <td>sadness</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Funeral ceremony...gloomy friday...</td>\n      <td>sadness</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>@dannycastillo We want to trade with someone w...</td>\n      <td>neutral</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>I should be sleep, but im not! thinking about ...</td>\n      <td>sadness</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>@charviray Charlene my love. I miss you</td>\n      <td>sadness</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"X = new_df['content']\nnlp = spacy.load(\"en_core_web_sm\")\n\nX_processed = []\nfor text in X:\n    doc = nlp(text)\n    processed_text = ' '.join([token.lemma_ for token in doc if not token.is_stop])\n    X_processed.append(processed_text)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import spacy\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.svm import SVR\n\n# Load the spaCy model\n\nsadness = new_df['sadness']\nneutral = new_df['neutral']\nlove = new_df['love']\nhappiness = new_df['happiness']\nanger = new_df['anger']\n\n# Split the data into training and testing sets\nX_train1, X_test1, y_train1, y_test1 = train_test_split(X_processed, sadness, test_size=0.2, random_state=42)\nX_train2, X_test2, y_train2, y_test2 = train_test_split(X_processed, neutral, test_size=0.2, random_state=42)\nX_train3, X_test3, y_train3, y_test3 = train_test_split(X_processed, love, test_size=0.2, random_state=42)\nX_train4, X_test4, y_train4, y_test4 = train_test_split(X_processed, happiness, test_size=0.2, random_state=42)\nX_train5, X_test5, y_train5, y_test5 = train_test_split(X_processed, anger, test_size=0.2, random_state=42)\n\n# Vectorize the text data\nvectorizer = TfidfVectorizer()\nX_train_vectorized = vectorizer.fit_transform(X_train1)\nX_test_vectorized = vectorizer.transform(X_test1)\n\n# Train the model\nsadness_m = SVR(kernel='linear')\nsadness_m.fit(X_train_vectorized, y_train1)\n\nneutral_m = SVR(kernel='linear')\nneutral_m.fit(X_train_vectorized, y_train2)\n\nlove_m = SVR(kernel='linear')\nlove_m.fit(X_train_vectorized, y_train3)\n\nhappiness_m = SVR(kernel='linear')\nhappiness_m.fit(X_train_vectorized, y_train4)\n\nanger_m = SVR(kernel='linear')\nanger_m.fit(X_train_vectorized, y_train5)\n\n# Test the model\ninput_tweet = \"I had a really good day, it was nice and I had a coffee\"\ninput_processed = ' '.join([token.lemma_ for token in nlp(input_tweet) if not token.is_stop])\ninput_vectorized = vectorizer.transform([input_processed])\nhappiness_score = happiness_m.predict(input_vectorized)[0]\n\n# Happiness score is a continuous value between 0 and 1\nprint(f\"The happiness score for the input tweet is: {happiness_score}\")\n","metadata":{"execution":{"iopub.status.busy":"2023-10-27T18:30:01.603997Z","iopub.execute_input":"2023-10-27T18:30:01.604403Z","iopub.status.idle":"2023-10-27T18:39:56.867442Z","shell.execute_reply.started":"2023-10-27T18:30:01.604373Z","shell.execute_reply":"2023-10-27T18:39:56.865635Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"The happiness score for the input tweet is: 0.5407923354518853\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_tweet = \"I had a nice day, I dont' know what to do now, I met a cute girl\"\ninput_processed = ' '.join([token.lemma_ for token in nlp(input_tweet) if not token.is_stop])\ninput_vectorized = vectorizer.transform([input_processed])\nprint(anger_m.predict(input_vectorized)[0])\nprint(sadness_m.predict(input_vectorized)[0])\nprint(neutral_m.predict(input_vectorized)[0])\nprint(happiness_m.predict(input_vectorized)[0])\nprint(love_m.predict(input_vectorized)[0])\n","metadata":{"execution":{"iopub.status.busy":"2023-10-28T09:23:45.979221Z","iopub.execute_input":"2023-10-28T09:23:45.979612Z","iopub.status.idle":"2023-10-28T09:23:46.249632Z","shell.execute_reply.started":"2023-10-28T09:23:45.979581Z","shell.execute_reply":"2023-10-28T09:23:46.248455Z"},"trusted":true},"execution_count":1,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m input_tweet \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI had a nice day, I dont\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m know what to do now, I met a cute girl\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m input_processed \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([token\u001b[38;5;241m.\u001b[39mlemma_ \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m \u001b[43mnlp\u001b[49m(input_tweet) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m token\u001b[38;5;241m.\u001b[39mis_stop])\n\u001b[1;32m      3\u001b[0m input_vectorized \u001b[38;5;241m=\u001b[39m vectorizer\u001b[38;5;241m.\u001b[39mtransform([input_processed])\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(anger_m\u001b[38;5;241m.\u001b[39mpredict(input_vectorized)[\u001b[38;5;241m0\u001b[39m])\n","\u001b[0;31mNameError\u001b[0m: name 'nlp' is not defined"],"ename":"NameError","evalue":"name 'nlp' is not defined","output_type":"error"}]},{"cell_type":"code","source":"import pickle\n\nmodel = \"happiness.pkl\"  \n\nwith open(model, 'wb') as file:  \n    pickle.dump(happiness_m, file)\n\nmodel = \"saddness.pkl\"  \n\nwith open(model, 'wb') as file:  \n    pickle.dump(sadness_m, file)\n\nmodel = \"anger.pkl\"  \n\nwith open(model, 'wb') as file:  \n    pickle.dump(anger_m, file)\n\nmodel = \"love.pkl\"  \n\nwith open(model, 'wb') as file:  \n    pickle.dump(love_m, file)\n\nmodel = \"nuetral.pkl\"  \n\nwith open(model, 'wb') as file:  \n    pickle.dump(neutral_m, file)\n","metadata":{"execution":{"iopub.status.busy":"2023-10-27T18:49:50.805867Z","iopub.execute_input":"2023-10-27T18:49:50.806250Z","iopub.status.idle":"2023-10-27T18:49:50.825548Z","shell.execute_reply.started":"2023-10-27T18:49:50.806220Z","shell.execute_reply":"2023-10-27T18:49:50.824344Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"with open('vectorizer.pkl', 'wb') as fin:\n    pickle.dump(vectorizer, fin)","metadata":{"execution":{"iopub.status.busy":"2023-10-27T19:09:36.545745Z","iopub.execute_input":"2023-10-27T19:09:36.546185Z","iopub.status.idle":"2023-10-27T19:09:36.562392Z","shell.execute_reply.started":"2023-10-27T19:09:36.546154Z","shell.execute_reply":"2023-10-27T19:09:36.561028Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}